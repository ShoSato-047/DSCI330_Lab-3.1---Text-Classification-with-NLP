{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShoSato-047/DSCI330_Lab-3.1---Text-Classification-with-NLP/blob/main/DSCI330_lab3_1_text_classification_w_NLP_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = red>**BoW vs. TF-IDF:**\n",
        "- Use BoW when you need a simple word frequency representation.\n",
        "- Use TF-IDF when you want to weigh words based on importance across documents."
      ],
      "metadata": {
        "id": "CjzZU3BxzP0A"
      },
      "id": "CjzZU3BxzP0A"
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "25ef8595-3418-4e44-99c4-048330182d3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25ef8595-3418-4e44-99c4-048330182d3f",
        "outputId": "a9b7e877-8e83-4f16-916b-522840ec04b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install composable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W1SFtCHzd79",
        "outputId": "d33dfa51-04fa-4ac7-919c-1020e8013016"
      },
      "id": "6W1SFtCHzd79",
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: composable in /usr/local/lib/python3.11/dist-packages (0.5.4)\n",
            "Requirement already satisfied: python-forge<19.0,>=18.6 in /usr/local/lib/python3.11/dist-packages (from composable) (18.6.0)\n",
            "Requirement already satisfied: toolz<0.12.0,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from composable) (0.11.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "f8a8cdf1-1bce-4915-9a45-fcf072ea00b2",
      "metadata": {
        "id": "f8a8cdf1-1bce-4915-9a45-fcf072ea00b2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import composable_records as rec\n",
        "import composable_tuples as tup\n",
        "\n",
        "from composable import pipeable\n",
        "from composable.strict import map, filter\n",
        "from composable_utility import apply, identity, get\n",
        "from composable_object import obj\n",
        "\n",
        "from composable_glob import glob\n",
        "from composable_utility import get, with_open, identity, apply\n",
        "\n",
        "# You may need to install utility.py to use \"with_open\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the root directory\n",
        "!pwd"
      ],
      "metadata": {
        "id": "ye0mWojl7DwA",
        "outputId": "bff99f6f-f719-4523-ddb0-8bcc5769ff24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ye0mWojl7DwA",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31f3e62d-8aae-4a16-868f-c8dfc9e9becd",
      "metadata": {
        "id": "31f3e62d-8aae-4a16-868f-c8dfc9e9becd"
      },
      "source": [
        "## Loading the emotions dataset\n",
        "\n",
        "The following data set include a large number of sentences combined with a classification of the emotion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "1793c54d-1179-4111-ab5e-e08e9dbc6c08",
      "metadata": {
        "id": "1793c54d-1179-4111-ab5e-e08e9dbc6c08"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "emotions = load_dataset(\"emotion\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "f97c30ec-9fc3-4771-9bcf-34e712a6dba3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f97c30ec-9fc3-4771-9bcf-34e712a6dba3",
        "outputId": "9fd435dc-028d-4125-e7eb-dc7599d5119a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 16000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "3f944535-d332-4da7-b624-56d4c049c4fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f944535-d332-4da7-b624-56d4c049c4fb",
        "outputId": "afec1806-0a76-4593-f274-60a85ecb3098"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 16000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "(train_ds := emotions >> get('train')) #getting training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "0e040da0-9806-4863-a894-11189d49c7e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e040da0-9806-4863-a894-11189d49c7e6",
        "outputId": "49d80c37-ea13-439b-bbdb-04847697d820"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['text', 'label']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "train_ds.column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "9785c036-f4f4-4c64-9d8d-b7626d178a42",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9785c036-f4f4-4c64-9d8d-b7626d178a42",
        "outputId": "566b339d-6b0f-429f-c799-e8459090fcca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "train_ds.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "b25f8a9b-d698-4e2d-8a03-f2308807526e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b25f8a9b-d698-4e2d-8a03-f2308807526e",
        "outputId": "ed550c94-712b-40c1-ef2f-65a8abee8cad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ['i didnt feel humiliated',\n",
              "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
              "  'im grabbing a minute to post i feel greedy wrong',\n",
              "  'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
              "  'i am feeling grouchy'],\n",
              " 'label': [0, 0, 3, 2, 3]}"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "train_ds[:5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "GXH6_omOgdLd",
        "outputId": "fade62a5-0f15-4872-ffbf-4b6cdf04a39a"
      },
      "id": "GXH6_omOgdLd",
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>datasets.arrow_dataset.Dataset</b><br/>def __init__(arrow_table: Table, info: Optional[DatasetInfo]=None, split: Optional[NamedSplit]=None, indices_table: Optional[Table]=None, fingerprint: Optional[str]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py</a>A Dataset backed by an Arrow table.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 628);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab241e0e-7536-4ca4-a1bd-e61a0716b827",
      "metadata": {
        "id": "ab241e0e-7536-4ca4-a1bd-e61a0716b827"
      },
      "source": [
        "### **Preparing the dataset**\n",
        "<font color = red>\"documents\" and \"labels\" are the 2 inputs you need to run the ML model in this example. They are both 'list' data type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "11294a45-3901-4432-922c-15ef15f2ba98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11294a45-3901-4432-922c-15ef15f2ba98",
        "outputId": "8f3bfa7f-ac08-4a83-8cca-eeef4ee69a8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i didnt feel humiliated',\n",
              " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
              " 'im grabbing a minute to post i feel greedy wrong',\n",
              " 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
              " 'i am feeling grouchy']"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "(documents :=\n",
        " train_ds\n",
        " >> get('text')\n",
        ") >> tup.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14Szv4QcjN11",
        "outputId": "021df5ac-19d1-473d-c3ec-a368d8f5bfaf"
      },
      "id": "14Szv4QcjN11",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "7e7bcad8-0436-4fbf-8c63-c4d364ec89f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e7bcad8-0436-4fbf-8c63-c4d364ec89f9",
        "outputId": "12d76f78-2034-488e-f191-2256d2553f44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 3, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "(labels :=\n",
        " train_ds\n",
        " >> get('label')\n",
        ") >> tup.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_ZX6_YkjRuB",
        "outputId": "65161760-172c-4d09-c488-aa3266bdd6ea"
      },
      "id": "a_ZX6_YkjRuB",
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96f39040-f15f-4ccc-97bb-648c334fecc1",
      "metadata": {
        "id": "96f39040-f15f-4ccc-97bb-648c334fecc1"
      },
      "source": [
        "### Bag of Words"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bag of Words:**\n",
        "In Bag of Words (BoW), the higher the value, the more frequently a word appears in a document.\n",
        "\n",
        "The score is not limited to a range of 0 to 1. The values represent raw word counts, meaning they can be any non-negative integer starting from 0 and increasing based on how often a word appears in a document.\n",
        "\n",
        "- Minimum: 0 (if the word is absent in a document)\n",
        "- Maximum: No fixed upper limit (depends on how frequently a word appears)"
      ],
      "metadata": {
        "id": "PHzM9KlY0fDa"
      },
      "id": "PHzM9KlY0fDa"
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "93641b34-6fa7-4859-9a40-1295a10e951f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93641b34-6fa7-4859-9a40-1295a10e951f",
        "outputId": "2c62627e-2cd5-4132-dc8a-a21789b535b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7375"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create the sparse feature set\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Create a training and test (validation) set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Train the model\n",
        "classifier = MultinomialNB()\n",
        "\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "(accuracy := accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b6d915b-75d7-4f27-b1f3-bed1d79ebde5",
      "metadata": {
        "id": "8b6d915b-75d7-4f27-b1f3-bed1d79ebde5"
      },
      "source": [
        "### TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TF-IDF Formula:**\n",
        "\n",
        "**TF-IDF = TF Ã— IDF**\n",
        "\n",
        "Where:\n",
        "\n",
        "- Term Frequency (TF): Measures how often a term appears in a document.\n",
        "- Inverse Document Frequency (IDF): Measures how rare a term is across documents.\n",
        "\n",
        "Note:\n",
        "- Minimum Score: 0 - If a word does not appear in a document, its score is 0.\n",
        "- If *TfidfVectorizer* uses **L2 normalization** (default in scikit-learn), TF-IDF values are scaled to range between 0 and 1 for each document."
      ],
      "metadata": {
        "id": "KZqtM8PqyPwC"
      },
      "id": "KZqtM8PqyPwC"
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "id": "45044ca8-2bcc-47c4-aab6-7babad73569d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45044ca8-2bcc-47c4-aab6-7babad73569d",
        "outputId": "8e72cbd0-1952-4433-cf13-72116a6690df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6165625"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create the sparse feature set\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Create a training and test (validation) set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Train the model\n",
        "classifier = MultinomialNB()\n",
        "\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "(accuracy := accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color=\"red\"> Exercise 3.6.1 </font>\n",
        "\n",
        "The file `train.csv` contains bits of text from three classic authors in the horror genre ([source](https://www.kaggle.com/c/spooky-author-identification/)).\n",
        "\n",
        "**Preprocessing Tasks.**\n",
        "1. Read the raw lines in using `with_open`.\n",
        "2. Split the data into columns and extract the text into one list and the labels into other.\n",
        "3. Clean up the text by making it lower case and removing any punctuation.\n",
        "4. Map the text labels to numbers.\n",
        "\n",
        "**ML tasks.** Test the performance of the naive Bayes classifer on both the Bag of Words and TF-IDF features."
      ],
      "metadata": {
        "id": "NVIzI4rp0sEn"
      },
      "id": "NVIzI4rp0sEn"
    },
    {
      "cell_type": "code",
      "source": [
        "# Question:\n",
        "\n",
        "# Your objective is to accurately identify the author of the sentences in the test set?\n",
        "\n",
        "# What do you mean by labels? Is this a list of specific words for each author?\n",
        "# We had a list of label ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'] in emotions dataset.\n",
        "# Where can I find a list of labels?\n",
        "\n",
        "# Am I supposed to split the text for each author?"
      ],
      "metadata": {
        "id": "Y78tMyqZBdgr"
      },
      "id": "Y78tMyqZBdgr",
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "XxRXQXUv1yj_"
      },
      "id": "XxRXQXUv1yj_",
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1: Read the raw lines in using with_open**"
      ],
      "metadata": {
        "id": "zXC6IpsyrHSH"
      },
      "id": "zXC6IpsyrHSH"
    },
    {
      "cell_type": "code",
      "source": [
        "# This is my current location (root)\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKBCp8JY_EXw",
        "outputId": "a2412f2a-1443-43f9-db61-049d3115f287"
      },
      "id": "jKBCp8JY_EXw",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(paths :=\n",
        " \"/content/train.csv\"\n",
        " >> glob()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHDxrXX3_C23",
        "outputId": "9eb88a81-d16f-4c72-9297-6377218e78ee"
      },
      "id": "nHDxrXX3_C23",
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/train.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(paths[0], encoding =\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "lines[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phppdOLq--p2",
        "outputId": "9b20753d-c0fe-42ce-be67-bb96865e597a"
      },
      "id": "phppdOLq--p2",
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"id\",\"text\",\"author\"\\n',\n",
              " '\"id26305\",\"This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.\",\"EAP\"\\n',\n",
              " '\"id17569\",\"It never once occurred to me that the fumbling might be a mere mistake.\",\"HPL\"\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2: Split the data into columns and extract the text into one list and the labels into other**"
      ],
      "metadata": {
        "id": "IBPh08bPrTX-"
      },
      "id": "IBPh08bPrTX-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint: Replace ',' with '-' in each line\n",
        "lines = [line.replace(', ', '- ') for line in lines]\n",
        "lines[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XubaTeOI_sM0",
        "outputId": "2dd2cd28-5a84-47b7-e12b-a1ef3cf36dc5"
      },
      "id": "XubaTeOI_sM0",
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"id\",\"text\",\"author\"\\n',\n",
              " '\"id26305\",\"This process- however- afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit- and return to the point whence I set out- without being aware of the fact; so perfectly uniform seemed the wall.\",\"EAP\"\\n',\n",
              " '\"id17569\",\"It never once occurred to me that the fumbling might be a mere mistake.\",\"HPL\"\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_lines = [line.split(',') for line in lines]\n",
        "split_lines[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKgfYb8t-gyo",
        "outputId": "23058925-aa33-48ef-8de2-4e519b14e989"
      },
      "id": "tKgfYb8t-gyo",
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['\"id\"', '\"text\"', '\"author\"\\n'],\n",
              " ['\"id26305\"',\n",
              "  '\"This process- however- afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit- and return to the point whence I set out- without being aware of the fact; so perfectly uniform seemed the wall.\"',\n",
              "  '\"EAP\"\\n'],\n",
              " ['\"id17569\"',\n",
              "  '\"It never once occurred to me that the fumbling might be a mere mistake.\"',\n",
              "  '\"HPL\"\\n']]"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a record\n",
        "records = []\n",
        "for row in split_lines[1:]:  # Skip header\n",
        "    record = {\n",
        "        \"id\": row[0].replace('\"', ''),\n",
        "        \"text\": row[1].replace('\"', ''),\n",
        "        \"author\": row[2].replace('\"', '').replace('\\n', '')\n",
        "    }\n",
        "    records.append(record)\n",
        "\n",
        "records[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q9waJd6BM0U",
        "outputId": "1f5eed34-c671-444b-b753-972709cb6162"
      },
      "id": "9Q9waJd6BM0U",
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 'id26305',\n",
              "  'text': 'This process- however- afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit- and return to the point whence I set out- without being aware of the fact; so perfectly uniform seemed the wall.',\n",
              "  'author': 'EAP'},\n",
              " {'id': 'id17569',\n",
              "  'text': 'It never once occurred to me that the fumbling might be a mere mistake.',\n",
              "  'author': 'HPL'},\n",
              " {'id': 'id11008',\n",
              "  'text': 'In his left hand was a gold snuff box- from which- as he capered down the hill- cutting all manner of fantastic steps- he took snuff incessantly with an air of the greatest possible self satisfaction.',\n",
              "  'author': 'EAP'}]"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# double check if my records work correctly\n",
        "records[0]['id']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "71se1opCOdXe",
        "outputId": "ce8da003-48c2-4478-f491-d8c5262cc419"
      },
      "id": "71se1opCOdXe",
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'id26305'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 3: Clean up the text by making it lower case and removing any punctuation.**"
      ],
      "metadata": {
        "id": "DCkQvVvhIv8j"
      },
      "id": "DCkQvVvhIv8j"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Comprehensions Solution:**"
      ],
      "metadata": {
        "id": "S5E1KxPygK2i"
      },
      "id": "S5E1KxPygK2i"
    },
    {
      "cell_type": "code",
      "source": [
        "# Making text lowercase\n",
        "text_lower = [record['text'].lower() for record in records]\n",
        "text_lower[:3]"
      ],
      "metadata": {
        "id": "bvfFUIGlIx13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e6949e-4b92-4f42-d8d2-76d8ed388f95"
      },
      "id": "bvfFUIGlIx13",
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this process- however- afforded me no means of ascertaining the dimensions of my dungeon; as i might make its circuit- and return to the point whence i set out- without being aware of the fact; so perfectly uniform seemed the wall.',\n",
              " 'it never once occurred to me that the fumbling might be a mere mistake.',\n",
              " 'in his left hand was a gold snuff box- from which- as he capered down the hill- cutting all manner of fantastic steps- he took snuff incessantly with an air of the greatest possible self satisfaction.']"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaXYLOrRsdoI",
        "outputId": "bc5de103-8932-4ab4-f976-0cfe5958be63"
      },
      "id": "SaXYLOrRsdoI",
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing a list of sentence into words\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text_words = [word_tokenize(record['text']) for record in records]\n",
        "text_words[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVzap9AQsBtE",
        "outputId": "e24598a6-70c5-4fad-db72-0553e7f31403"
      },
      "id": "qVzap9AQsBtE",
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['This',\n",
              "  'process-',\n",
              "  'however-',\n",
              "  'afforded',\n",
              "  'me',\n",
              "  'no',\n",
              "  'means',\n",
              "  'of',\n",
              "  'ascertaining',\n",
              "  'the',\n",
              "  'dimensions',\n",
              "  'of',\n",
              "  'my',\n",
              "  'dungeon',\n",
              "  ';',\n",
              "  'as',\n",
              "  'I',\n",
              "  'might',\n",
              "  'make',\n",
              "  'its',\n",
              "  'circuit-',\n",
              "  'and',\n",
              "  'return',\n",
              "  'to',\n",
              "  'the',\n",
              "  'point',\n",
              "  'whence',\n",
              "  'I',\n",
              "  'set',\n",
              "  'out-',\n",
              "  'without',\n",
              "  'being',\n",
              "  'aware',\n",
              "  'of',\n",
              "  'the',\n",
              "  'fact',\n",
              "  ';',\n",
              "  'so',\n",
              "  'perfectly',\n",
              "  'uniform',\n",
              "  'seemed',\n",
              "  'the',\n",
              "  'wall',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing any punctuation\n",
        "punctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~'\n",
        "\n",
        "from string import punctuation\n",
        "\n",
        "(punc_map := str.maketrans('', '', punctuation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bRtDwQ8J_tU",
        "outputId": "b66e32c7-0b30-4dc3-d5ea-da439a0fde2c"
      },
      "id": "6bRtDwQ8J_tU",
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{33: None,\n",
              " 34: None,\n",
              " 35: None,\n",
              " 36: None,\n",
              " 37: None,\n",
              " 38: None,\n",
              " 39: None,\n",
              " 40: None,\n",
              " 41: None,\n",
              " 42: None,\n",
              " 43: None,\n",
              " 44: None,\n",
              " 45: None,\n",
              " 46: None,\n",
              " 47: None,\n",
              " 58: None,\n",
              " 59: None,\n",
              " 60: None,\n",
              " 61: None,\n",
              " 62: None,\n",
              " 63: None,\n",
              " 64: None,\n",
              " 91: None,\n",
              " 92: None,\n",
              " 93: None,\n",
              " 94: None,\n",
              " 95: None,\n",
              " 96: None,\n",
              " 123: None,\n",
              " 124: None,\n",
              " 125: None,\n",
              " 126: None}"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing punctuation from each word in the tokenized lists\n",
        "text_no_punc = [[word.translate(punc_map) for word in words] for words in text_words]\n",
        "text_no_punc[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8UxuahJcLV",
        "outputId": "7e744e8d-dcd4-4fa0-aadc-38a3292e9ecd"
      },
      "id": "oi8UxuahJcLV",
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['This',\n",
              "  'process',\n",
              "  'however',\n",
              "  'afforded',\n",
              "  'me',\n",
              "  'no',\n",
              "  'means',\n",
              "  'of',\n",
              "  'ascertaining',\n",
              "  'the',\n",
              "  'dimensions',\n",
              "  'of',\n",
              "  'my',\n",
              "  'dungeon',\n",
              "  '',\n",
              "  'as',\n",
              "  'I',\n",
              "  'might',\n",
              "  'make',\n",
              "  'its',\n",
              "  'circuit',\n",
              "  'and',\n",
              "  'return',\n",
              "  'to',\n",
              "  'the',\n",
              "  'point',\n",
              "  'whence',\n",
              "  'I',\n",
              "  'set',\n",
              "  'out',\n",
              "  'without',\n",
              "  'being',\n",
              "  'aware',\n",
              "  'of',\n",
              "  'the',\n",
              "  'fact',\n",
              "  '',\n",
              "  'so',\n",
              "  'perfectly',\n",
              "  'uniform',\n",
              "  'seemed',\n",
              "  'the',\n",
              "  'wall',\n",
              "  '']]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Pipeable Solution:**"
      ],
      "metadata": {
        "id": "B17gJmG_gT4Z"
      },
      "id": "B17gJmG_gT4Z"
    },
    {
      "cell_type": "code",
      "source": [
        "# pipeable function for readability\n",
        "(clean_words :=\n",
        " [record['text'] for record in records]\n",
        " >> pipeable(lambda texts: [s.lower() for s in texts])\n",
        " >> pipeable(lambda texts: [s.translate(punc_map) for s in texts])\n",
        " #>> pipeable(lambda texts: [word_tokenize(s) for s in texts]) # tokenize into words\n",
        " >> pipeable(lambda texts: [' '.join(word_tokenize(s)) for s in texts]) # put tokenized words into a text\n",
        ")[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcXxavwqtDkb",
        "outputId": "e3bfe29c-fb3a-4ac9-9f1c-68cb76f9d15a"
      },
      "id": "CcXxavwqtDkb",
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this process however afforded me no means of ascertaining the dimensions of my dungeon as i might make its circuit and return to the point whence i set out without being aware of the fact so perfectly uniform seemed the wall',\n",
              " 'it never once occurred to me that the fumbling might be a mere mistake']"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 4: Map the text labels to numbers.**\n",
        "\n",
        "I need to combine clean_words with author in a single record before mapping numbers."
      ],
      "metadata": {
        "id": "vxrSHlc-2zaF"
      },
      "id": "vxrSHlc-2zaF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Lables from kaggle website - only 3 authors\n",
        "authors = ['EAP', 'HPL', 'MWS']\n",
        "author_map = {'EAP': 0, 'HPL': 1, 'MWS': 2}\n",
        "\n",
        "author_map"
      ],
      "metadata": {
        "id": "Njvoy1e023SF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49163b66-3f73-4378-d095-c9f64d86c9e5"
      },
      "id": "Njvoy1e023SF",
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'EAP': 0, 'HPL': 1, 'MWS': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine clean_words and author info into a record\n",
        "cleaned_data = [\n",
        "                {'text': text,\n",
        "                 'author': record['author'],\n",
        "                 'label': author_map.get(record['author'])\n",
        "                 }\n",
        "                for text, record in zip(clean_words, records)]\n",
        "\n",
        "cleaned_data[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYI7w9b1kBbY",
        "outputId": "d68fc325-a481-4675-8d0d-0a0ad3a6cd02"
      },
      "id": "QYI7w9b1kBbY",
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'this process however afforded me no means of ascertaining the dimensions of my dungeon as i might make its circuit and return to the point whence i set out without being aware of the fact so perfectly uniform seemed the wall',\n",
              "  'author': 'EAP',\n",
              "  'label': 0},\n",
              " {'text': 'it never once occurred to me that the fumbling might be a mere mistake',\n",
              "  'author': 'HPL',\n",
              "  'label': 1}]"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(cleaned_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRhda3ldgn5i",
        "outputId": "19d9d593-07a4-404c-a9b4-3b1cf25a34df"
      },
      "id": "TRhda3ldgn5i",
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data[0]['label']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx65DcfLgLgg",
        "outputId": "cd2d5b3d-1d9c-4ff9-ed7e-245ced06649d"
      },
      "id": "yx65DcfLgLgg",
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preparing the dataset (inputs for ML model)**"
      ],
      "metadata": {
        "id": "-Z29cOIfh3s0"
      },
      "id": "-Z29cOIfh3s0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract textss from cleaned_data\n",
        "my_documents = [record['text'] for record in cleaned_data]\n",
        "my_documents[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a2TiN33hpFZ",
        "outputId": "fdb1556a-4794-4996-8303-f116ccbc13cc"
      },
      "id": "6a2TiN33hpFZ",
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this process however afforded me no means of ascertaining the dimensions of my dungeon as i might make its circuit and return to the point whence i set out without being aware of the fact so perfectly uniform seemed the wall',\n",
              " 'it never once occurred to me that the fumbling might be a mere mistake']"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(my_documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txRfrxStjr-3",
        "outputId": "d7a625ce-74a5-443a-fe52-7d47027c6716"
      },
      "id": "txRfrxStjr-3",
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract labels from cleaned_data\n",
        "my_labels = [record['label'] for record in cleaned_data]\n",
        "my_labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwNlThdmhOPk",
        "outputId": "0ef1ae1a-7f0b-4ad6-b613-68b65a025f96"
      },
      "id": "qwNlThdmhOPk",
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 0, 2, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(my_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb0nZwtPjusf",
        "outputId": "9eec4936-4e2b-46d0-c33a-c17638c1c2f2"
      },
      "id": "jb0nZwtPjusf",
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 5: Run the ML modles**"
      ],
      "metadata": {
        "id": "yZjz2jfSikiu"
      },
      "id": "yZjz2jfSikiu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Bag of Words:**"
      ],
      "metadata": {
        "id": "3muwHn0ZiqAA"
      },
      "id": "3muwHn0ZiqAA"
    },
    {
      "cell_type": "code",
      "source": [
        "# I may need to put tokenized words back to a single sentence"
      ],
      "metadata": {
        "id": "41FezciKlqRq"
      },
      "id": "41FezciKlqRq",
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create the sparse feature set\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X = vectorizer.fit_transform(my_documents)\n",
        "\n",
        "# Create a training and test (validation) set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, my_labels,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Train the model\n",
        "classifier = MultinomialNB()\n",
        "\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "(accuracy := accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "KMK1jRCCieyL",
        "outputId": "fb3c0557-a144-40b6-cc8f-f1f3ed194ea7"
      },
      "id": "KMK1jRCCieyL",
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'<' not supported between instances of 'int' and 'NoneType'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-182-b4f656930f06>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0mlabelbin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelbin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelbin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mof\u001b[0m \u001b[0mCSR\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \"\"\"\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \"\"\"\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_array_api_compliant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_unique.py\u001b[0m in \u001b[0;36mattach_unique\u001b[0;34m(return_tuple, *ys)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mInput\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0munique\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mattached\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \"\"\"\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_attach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_tuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_unique.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mInput\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0munique\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mattached\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \"\"\"\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_attach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_tuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_unique.py\u001b[0m in \u001b[0;36m_attach_unique\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0munique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0munique_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"unique\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munique_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_arraysetops_impl.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         ret = _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0m\u001b[1;32m    290\u001b[0m                         equal_nan=equal_nan, inverse_shape=ar.shape, axis=None)\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_arraysetops_impl.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan, inverse_shape, axis)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'NoneType'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **TF-IDF:**"
      ],
      "metadata": {
        "id": "Xu_zM66Ri1Dj"
      },
      "id": "Xu_zM66Ri1Dj"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m5-aixBni0xr"
      },
      "id": "m5-aixBni0xr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KZqtM8PqyPwC",
        "S5E1KxPygK2i"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}